{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlaq3-VDjV2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMh5645SkEHN",
        "outputId": "e207d2df-8fc4-4659-f258-373ecc2015f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fraction or fixed number of samples to use\n",
        "fraction = 0.1  # Use 10% of the data\n",
        "num_train_samples = int(len(x_train) * fraction)\n",
        "num_test_samples = int(len(x_test) * fraction)"
      ],
      "metadata": {
        "id": "zJ_qfKMrkQZ5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select a subset of training and testing data\n",
        "indices_train = np.random.choice(len(x_train), num_train_samples, replace=False)\n",
        "indices_test = np.random.choice(len(x_test), num_test_samples, replace=False)\n",
        "\n",
        "x_train_reduced, y_train_reduced = x_train[indices_train], y_train[indices_train]\n",
        "x_test_reduced, y_test_reduced = x_test[indices_test], y_test[indices_test]\n"
      ],
      "metadata": {
        "id": "Pmyp_NIrkVRl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print new dataset sizes\n",
        "print(f\"Reduced training set size: {x_train_reduced.shape}\")\n",
        "print(f\"Reduced testing set size: {x_test_reduced.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XbP--VVkWz9",
        "outputId": "b59c76b5-4bb5-4f34-c7cc-d388d2c19608"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced training set size: (5000, 32, 32, 3)\n",
            "Reduced testing set size: (1000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize images to [0, 1] range\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "i-htbnz4kaZY",
        "outputId": "7fc0ef34-2fe3-4ec7-b4a0-a7f90a6bb041"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b6eaadf14cf9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalize images to [0, 1] range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert RGB to Lab color space\n",
        "def rgb_to_lab(images):\n",
        "    return np.array([rgb2lab(img) for img in images])\n",
        "\n",
        "def preprocess_data(images):\n",
        "    lab_images = rgb_to_lab(images)\n",
        "    L = lab_images[..., 0] / 100.0  # Normalize L channel to [0, 1]\n",
        "    ab = lab_images[..., 1:] / 128.0  # Normalize a and b channels to [-1, 1]\n",
        "    return L[..., np.newaxis], ab\n",
        "\n",
        "L_train, ab_train = preprocess_data(X_train)\n",
        "L_test, ab_test = preprocess_data(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "qQ5yjT7vkfBC",
        "outputId": "18b01477-829d-41a4-f97a-8398cf15df37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-10f2e2cf1ce5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mL_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mL_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data for validation\n",
        "L_train, L_val, ab_train, ab_val = train_test_split(L_train, ab_train, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "81ihg36YkkLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "def build_colorization_model():\n",
        "    inputs = Input(shape=(32, 32, 1))"
      ],
      "metadata": {
        "id": "kE1fNs-Wko1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Encoder\n",
        "    x = Conv2D(64, (3, 3), padding='same', strides=1)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same', strides=2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same', strides=2)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)"
      ],
      "metadata": {
        "id": "ngidO2g8krgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Decoder\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    outputs = Conv2D(2, (3, 3), padding='same', activation='tanh')(x)  # Output ab channels\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = build_colorization_model()\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae']"
      ],
      "metadata": {
        "id": "3lX0Hz25kup8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "history = model.fit(\n",
        "    L_train, ab_train,\n",
        "    validation_data=(L_val, ab_val),\n",
        "    epochs=20,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "EdeibPSik07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in HDF5 format\n",
        "model.save(\"colorization_model.h5\")\n",
        "print(\"Model saved as colorization_model.h5\")"
      ],
      "metadata": {
        "id": "B6J016U6k5UZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}